{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sistemas-de-Recomendación---Clase-IV\" data-toc-modified-id=\"Sistemas-de-Recomendación---Clase-IV-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sistemas de Recomendación - Clase IV</a></span></li><li><span><a href=\"#Implementación-de-un-FWLS\" data-toc-modified-id=\"Implementación-de-un-FWLS-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Implementación de un FWLS</a></span></li><li><span><a href=\"#Modelo-de-Filtrado-Colaborativo\" data-toc-modified-id=\"Modelo-de-Filtrado-Colaborativo-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modelo de Filtrado Colaborativo</a></span></li><li><span><a href=\"#Modelo-predictivo-basado-en-contenido\" data-toc-modified-id=\"Modelo-predictivo-basado-en-contenido-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modelo predictivo basado en contenido</a></span></li><li><span><a href=\"#Feature-Weighted-Linear-Stacking\" data-toc-modified-id=\"Feature-Weighted-Linear-Stacking-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Feature Weighted Linear Stacking</a></span><ul class=\"toc-item\"><li><span><a href=\"#Meta-atributos-de-modelos\" data-toc-modified-id=\"Meta-atributos-de-modelos-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Meta atributos de modelos</a></span></li><li><span><a href=\"#Funciones-atributo\" data-toc-modified-id=\"Funciones-atributo-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Funciones atributo</a></span></li><li><span><a href=\"#Generación-de-atributos-de-entrenamiento\" data-toc-modified-id=\"Generación-de-atributos-de-entrenamiento-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Generación de atributos de entrenamiento</a></span></li><li><span><a href=\"#Entrenamiento-del-modelo\" data-toc-modified-id=\"Entrenamiento-del-modelo-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Entrenamiento del modelo</a></span></li><li><span><a href=\"#Evaluación-del-modelo\" data-toc-modified-id=\"Evaluación-del-modelo-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Evaluación del modelo</a></span></li><li><span><a href=\"#Comparación-de-los-modelos\" data-toc-modified-id=\"Comparación-de-los-modelos-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Comparación de los modelos</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"font-size:2.5em;text-align:center;\">Sistemas de Recomendación - Clase IV</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementación de un FWLS\n",
    "\n",
    "En este notebook veremos los pasos para crear (y evaluar) un modelo de Ensemble de **Feature Weighted Linear Stacking** basado en dos sistemas de recomendación: un filtrado colaborativo y un filtrado por contenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelo de Filtrado Colaborativo\n",
    "\n",
    "Para el primer modelo vamos a utilizar [Surpr!se](http://surpriselib.com/) como lo venimos haciendo. Además, haremos uso de su sistema de `Dataset`s que nos serviará para la división del conjunto de datos en entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "reader = Reader(rating_scale=(ratings.rating.min(), ratings.rating.max()))\n",
    "ratings = Dataset.load_from_df(ratings[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "ratings_train, ratings_test = train_test_split(ratings, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Notar que en este casos el filtrado es basado en items (películas), en lugar de usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cf_model = KNNWithMeans(k=5, sim_options={\"user_based\": False, \"name\": \"pearson\"}).fit(ratings_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelo predictivo basado en contenido\n",
    "\n",
    "Primero debemos crear nuestro modelo predictivo basado en información de contenido. En este caso, basado en los géneros de las películas. La idea es, a partir de los géneros de las películas, buscar aquellas más similares. Luego, en base a los ratings hechos por un usuario, se pueden generar ratings usando algún algoritmo clásico de KNearestNeigbors y en base a ello devolver lo predicho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class GenresBasedFilter(object):\n",
    "    def __init__(self, movies, k=5):\n",
    "        self.movie_to_idx = {row[\"movieId\"]: idx for idx, row in movies.iterrows()}\n",
    "        self.idx_to_movie = {idx: movie for movie, idx in self.movie_to_idx.items()}\n",
    "        self.k = k\n",
    "\n",
    "        genres = set(g for G in movies['genres'] for g in G)\n",
    "        for g in genres:\n",
    "            movies[g] = movies.genres.transform(lambda x: int(g in x))\n",
    "\n",
    "        self.movie_genres = movies.drop(columns=['movieId', 'title', 'genres'])\n",
    "\n",
    "    def fit(self, ratings):\n",
    "        self.movies_cosine_sim_ = cosine_similarity(self.movie_genres, self.movie_genres)\n",
    "\n",
    "        self.user_ratings_ = {}\n",
    "        for (user_id, movie_id, rating) in ratings.build_testset():\n",
    "            if user_id not in self.user_ratings_:\n",
    "                self.user_ratings_[user_id] = {}\n",
    "            self.user_ratings_[user_id][movie_id] = rating\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, user, movie):\n",
    "        if not user in self.user_ratings_ or not movie in self.movie_to_idx:\n",
    "            global_mean = np.mean([\n",
    "                rating for movies in self.user_ratings_.values() for rating in movies.values()\n",
    "            ])\n",
    "            return global_mean\n",
    "\n",
    "        movie_idx = self.movie_to_idx[movie]\n",
    "        sim_scores = list(enumerate(self.movies_cosine_sim_[movie_idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:]\n",
    "\n",
    "        sims = []\n",
    "\n",
    "        for movie, score in sim_scores:\n",
    "            if self.idx_to_movie[movie] in self.user_ratings_[user]:\n",
    "                sims.append((self.user_ratings_[user][self.idx_to_movie[movie]], score))\n",
    "                if len(sims) >= self.k:\n",
    "                    break\n",
    "\n",
    "        user_mean = np.mean(list(self.user_ratings_[user].values()))\n",
    "\n",
    "        pred = 0\n",
    "        sim_sum = 0\n",
    "\n",
    "        for rating, score in sims:\n",
    "            pred += score * (rating - user_mean)\n",
    "            sim_sum += score\n",
    "\n",
    "        if sim_sum == 0:\n",
    "            return user_mean\n",
    "\n",
    "        return user_mean + pred / sim_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Para este modelo cargamos el conjunto de datos que tiene información de los géneros de las películas. Necesitamos esta información para calcular la matriz de similitud coseno. Por otra parte, utilizamos el conjunto de entrenamiento de Surpr!se para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"../data/ml-latest-small/movies.csv\")\n",
    "movies['genres'] = movies['genres'].apply(lambda x: x.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cb_model = GenresBasedFilter(movies).fit(ratings_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Weighted Linear Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Meta atributos de modelos\n",
    "\n",
    "Con nuestros dos modelos bases, pasamos a crear nuestro modelo FWLS. Para ello, lo primero que tenemos que hacer es transformar los meta atributos de los modelos a partir de la información de usuario y película (esto lleva un tiempo, porque el algoritmo de filtrado por contenido no está optimizado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "transformed_ratings_train = []\n",
    "\n",
    "for u, m, r in tqdm_notebook(ratings_train.build_testset()):\n",
    "    transformed_ratings_train.append({\n",
    "        \"userId\": u,\n",
    "        \"movieId\": m,\n",
    "        \"cb_rating\": cb_model.predict(u, m),\n",
    "        \"cf_rating\": cf_model.predict(u, m).est,\n",
    "        \"rating\": r\n",
    "    })\n",
    "\n",
    "transformed_ratings_train = pd.DataFrame(transformed_ratings_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Funciones atributo\n",
    "\n",
    "El siguiente paso se basa en definir nuestras funciones atributo que se le darán en conjunto a los meta atributos de los modelos para entrenar el algoritmo de regresión logística. En este caso solo definiremos tres muy sencillas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "user_mean_rating = defaultdict(\n",
    "    lambda: transformed_ratings_train[\"rating\"].mean(),\n",
    "    transformed_ratings_train.groupby(\"userId\")[\"rating\"].mean().to_dict()\n",
    ")\n",
    "user_num_rating = defaultdict(\n",
    "    lambda: 0,\n",
    "    transformed_ratings_train.groupby(\"userId\").size().to_dict()\n",
    ")\n",
    "\n",
    "def feature_function_constant():\n",
    "    return 1\n",
    "\n",
    "def feature_function_mean(user_id):\n",
    "    return user_mean_rating[user_id]\n",
    "\n",
    "def feature_function_over(user_id, min_ratings=3):\n",
    "    return int(user_num_rating[user_id] >= min_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generación de atributos de entrenamiento\n",
    "\n",
    "A partir de nuestros meta atributos de lo modelos y nuestras funciones atributo, podemos definir nuestros atributos finales que serán utilizados en el modelo de regresión logística. Para ello tenemos que aplicar las funciones atributo a los meta atributos de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for base_model in [\"cb\", \"cf\"]:\n",
    "    transformed_ratings_train[\"{}_rating_fc\".format(base_model)] =\\\n",
    "        transformed_ratings_train.apply(\n",
    "            lambda row: row[\"{}_rating\".format(base_model)] * feature_function_constant(),\n",
    "            axis=1\n",
    "        )\n",
    "    transformed_ratings_train[\"{}_rating_fm\".format(base_model)] =\\\n",
    "        transformed_ratings_train.apply(\n",
    "            lambda row: row[\"{}_rating\".format(base_model)] * feature_function_mean(row[\"userId\"]),\n",
    "            axis=1\n",
    "        )\n",
    "    transformed_ratings_train[\"{}_rating_fo\".format(base_model)] =\\\n",
    "        transformed_ratings_train.apply(\n",
    "            lambda row: row[\"{}_rating\".format(base_model)] * feature_function_over(row[\"userId\"]),\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "El último paso es el entrenamiento del modelo de regresión lineal en base a nuestros atributos generados en el paso anterior. Este es el paso más sencillo porque utilizamos directamente el algoritmo de `scikit-learn` para regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "fwls_model = LinearRegression()\n",
    "\n",
    "feature_cols = [\"{}_rating_{}\".format(fm, ff) for fm in [\"cb\", \"cf\"] for ff in [\"fc\", \"fo\", \"fm\"]]\n",
    "\n",
    "fwls_model.fit(\n",
    "    transformed_ratings_train[feature_cols],\n",
    "    transformed_ratings_train[\"rating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "Para evaluar los modelos tenemos que realizar el mismo paso de transformación sobre los datos de evaluación que se utilizaron para los datos de entrenamiento. Empezando por la obtención de meta atributos de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "transformed_ratings_test = []\n",
    "\n",
    "for u, m, r in tqdm_notebook(ratings_test):\n",
    "    transformed_ratings_test.append({\n",
    "        \"userId\": u,\n",
    "        \"movieId\": m,\n",
    "        \"cb_rating\": cb_model.predict(u, m),\n",
    "        \"cf_rating\": cf_model.predict(u, m).est,\n",
    "        \"rating\": r\n",
    "    })\n",
    "\n",
    "transformed_ratings_test = pd.DataFrame(transformed_ratings_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y siguiendo por los atributos a partir de las funciones atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for base_model in [\"cb\", \"cf\"]:\n",
    "    transformed_ratings_test[\"{}_rating_fc\".format(base_model)] =\\\n",
    "        transformed_ratings_test.apply(\n",
    "            lambda row: row[\"{}_rating\".format(base_model)] * feature_function_constant(),\n",
    "            axis=1\n",
    "        )\n",
    "    transformed_ratings_test[\"{}_rating_fm\".format(base_model)] =\\\n",
    "        transformed_ratings_test.apply(\n",
    "            lambda row: row[\"{}_rating\".format(base_model)] * feature_function_mean(row[\"userId\"]),\n",
    "            axis=1\n",
    "        )\n",
    "    transformed_ratings_test[\"{}_rating_fo\".format(base_model)] =\\\n",
    "        transformed_ratings_test.apply(\n",
    "            lambda row: row[\"{}_rating\".format(base_model)] * feature_function_over(row[\"userId\"]),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "transformed_ratings_test[\"fwls_rating\"] = fwls_model.predict(transformed_ratings_test[feature_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Comparación de los modelos\n",
    "\n",
    "Finalmente, tenemos todo lo necesario para hacer una comparación (e.g. midiento el error) de los distintos modelos sobre el conjunto de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for model in [\"cf\", \"cb\", \"fwls\"]:\n",
    "    rmse = np.sqrt(\n",
    "        mean_squared_error(\n",
    "            transformed_ratings_test[\"rating\"],\n",
    "            transformed_ratings_test[\"{}_rating\".format(model)]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"RMSE for {} model: {:03f}\".format(model, rmse))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
